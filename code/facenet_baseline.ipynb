{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facenet baseline in Keras\n",
    "\n",
    "This is a very simple baseline with no training required. Instead, we'll use the pretrained Facenet model from this repo https://github.com/nyoki-mtl/keras-facenet . \n",
    "\n",
    "First, we compute the face embeddings for each image in the test set, then we compute the Euclidean distance for each image pair in the test dataframe. Finally, we convert the distance to a probability using cumulative probabilites based on the distribution of the distance itself on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "from scipy.spatial import distance\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/recognizing-faces-in-the-wild/train_relationships.csv\")\n",
    "test_df = pd.read_csv(\"../input/recognizing-faces-in-the-wild/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model_path = '../input/facenet-keras/facenet_keras.h5'\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's preprocessing stuff. The images from the test set seem to already be aligned, so I'll omit that part here for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "b8da009689331982f628256abc151cbbd7e288a1"
   },
   "outputs": [],
   "source": [
    "def prewhiten(x):\n",
    "    if x.ndim == 4:\n",
    "        axis = (1, 2, 3)\n",
    "        size = x[0].size\n",
    "    elif x.ndim == 3:\n",
    "        axis = (0, 1, 2)\n",
    "        size = x.size\n",
    "    else:\n",
    "        raise ValueError('Dimension should be 3 or 4')\n",
    "\n",
    "    mean = np.mean(x, axis=axis, keepdims=True)\n",
    "    std = np.std(x, axis=axis, keepdims=True)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
    "    y = (x - mean) / std_adj\n",
    "    return y\n",
    "\n",
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n",
    "    return output\n",
    "\n",
    "def load_and_align_images(filepaths, margin,image_size = 160):\n",
    "    \n",
    "    aligned_images = []\n",
    "    for filepath in filepaths:\n",
    "        img = imread(filepath)\n",
    "        aligned = resize(img, (image_size, image_size), mode='reflect')\n",
    "        aligned_images.append(aligned)\n",
    "            \n",
    "    return np.array(aligned_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll compute all the embeddings for the test images using the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "4d81f154869853bcc2fb8b1899094d97ba237c72"
   },
   "outputs": [],
   "source": [
    "def calc_embs(filepaths, margin=10, batch_size=512):\n",
    "    pd = []\n",
    "    for start in tqdm(range(0, len(filepaths), batch_size)):\n",
    "        aligned_images = prewhiten(load_and_align_images(filepaths[start:start+batch_size], margin))\n",
    "        pd.append(model.predict_on_batch(aligned_images))\n",
    "    embs = l2_normalize(np.concatenate(pd))\n",
    "\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [01:29<00:00,  5.69s/it]\n"
     ]
    }
   ],
   "source": [
    "test_images = os.listdir(\"../input/recognizing-faces-in-the-wild/test/\")\n",
    "test_embs = calc_embs([os.path.join(\"../input/recognizing-faces-in-the-wild/test/\", f) for f in test_images])\n",
    "np.save(\"test_embs.npy\", test_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "c65eb6eeef58b3e1c59a2a35890971245bbb4529"
   },
   "outputs": [],
   "source": [
    "test_df[\"distance\"] = 0\n",
    "img2idx = dict()\n",
    "for idx, img in enumerate(test_images):\n",
    "    img2idx[img] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the actual distance between provided image pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "1e2db3e5261a20466cb11b4bfc1273627abcfeb9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5310/5310 [00:02<00:00, 1845.83it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    imgs = [test_embs[img2idx[img]] for img in row.img_pair.split(\"-\")]\n",
    "    test_df.loc[idx, \"distance\"] = distance.euclidean(*imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we convert the distances to probabiliy values and submit the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_distances = test_df.distance.values\n",
    "sum_dist = np.sum(all_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5310/5310 [00:00<00:00, 34593.19it/s]\n"
     ]
    }
   ],
   "source": [
    "probs = []\n",
    "for dist in tqdm(all_distances):\n",
    "    prob = np.sum(all_distances[np.where(all_distances <= dist)[0]])/sum_dist\n",
    "    probs.append(1 - prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(\"../input/recognizing-faces-in-the-wild/sample_submission.csv\")\n",
    "sub_df.is_related = probs\n",
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
